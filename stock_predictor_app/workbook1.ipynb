{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import simfin as sf\n",
    "from simfin.names import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9104e\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "print(api_key[:5])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"us-companies\" on disk (13 days old).\n",
      "- Loading from disk ... Done!\n",
      "Dataset \"us-shareprices-daily\" on disk (13 days old).\n",
      "- Loading from disk ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/simfin/load.py:154: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  df = pd.read_csv(path, sep=';', header=0,\n",
      "/opt/anaconda3/lib/python3.12/site-packages/simfin/load.py:154: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  df = pd.read_csv(path, sep=';', header=0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set SimFin data directory\n",
    "sf.set_api_key(api_key)\n",
    "\n",
    "sf.set_data_dir('/Users/ayushsingh/Desktop/MBD/Python 2/Group Assignment/simfin_data/')\n",
    "\n",
    "# Load datasets\n",
    "df_companies = sf.load_companies(market='us')\n",
    "df_share_prices = sf.load_shareprices(market='us', variant='daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class ETL:\n",
    "    def __init__(self, share_prices_df, companies_df, tickers, output_file='filtered_5_companies_stock_data.csv'):\n",
    "        self.df_share_prices = share_prices_df.copy()\n",
    "        self.df_companies = companies_df.copy()\n",
    "        self.tickers = tickers\n",
    "        self.output_file = output_file\n",
    "        self.df_cleaned = None\n",
    "\n",
    "        # Final feature set\n",
    "        self.final_features = [\n",
    "            'ticker', 'date',\n",
    "            'open', 'high', 'low', 'close', 'adj. close', 'volume',\n",
    "            'daily_return', 'volatility',\n",
    "            '5_day_ma', '10_day_ma',\n",
    "            'trend', 'next_day_close'\n",
    "        ]\n",
    "\n",
    "    def reset_and_clean_columns(self):\n",
    "        self.df_share_prices.reset_index(inplace=True)\n",
    "        self.df_companies.reset_index(inplace=True)\n",
    "        self.df_share_prices.columns = self.df_share_prices.columns.str.lower()\n",
    "        self.df_companies.columns = self.df_companies.columns.str.lower()\n",
    "\n",
    "    def handle_dates_and_duplicates(self):\n",
    "        self.df_share_prices['date'] = pd.to_datetime(self.df_share_prices['date'], errors='coerce')\n",
    "        self.df_companies.drop_duplicates(inplace=True)\n",
    "        self.df_share_prices.drop_duplicates(inplace=True)\n",
    "\n",
    "    def handle_nulls_and_missing(self):\n",
    "        self.df_companies.ffill(inplace=True)\n",
    "        self.df_share_prices.ffill(inplace=True)\n",
    "        self.df_share_prices.dropna(subset=['close'], inplace=True)\n",
    "\n",
    "    def feature_engineering(self):\n",
    "        group = self.df_share_prices.groupby('ticker')\n",
    "\n",
    "        # Daily return\n",
    "        self.df_share_prices['daily_return'] = group['close'].pct_change()\n",
    "\n",
    "        # Volatility (7-day rolling std)\n",
    "        self.df_share_prices['volatility'] = group['close'].transform(lambda x: x.rolling(7).std())\n",
    "\n",
    "        # Moving averages\n",
    "        self.df_share_prices['5_day_ma'] = group['close'].transform(lambda x: x.rolling(5).mean())\n",
    "        self.df_share_prices['10_day_ma'] = group['close'].transform(lambda x: x.rolling(10).mean())\n",
    "\n",
    "        # Trend variable (classification target)\n",
    "        self.df_share_prices['trend'] = (self.df_share_prices['daily_return'] > 0).astype(int)\n",
    "\n",
    "        # Price prediction target\n",
    "        self.df_share_prices['next_day_close'] = group['close'].shift(-1)\n",
    "\n",
    "    def filter_data(self):\n",
    "        # Filter for selected tickers and last 3 years\n",
    "        three_years_ago = pd.Timestamp.today() - pd.DateOffset(years=3)\n",
    "        self.df_share_prices = self.df_share_prices[\n",
    "            (self.df_share_prices['ticker'].isin(self.tickers)) &\n",
    "            (self.df_share_prices['date'] >= three_years_ago)\n",
    "        ]\n",
    "        self.df_companies = self.df_companies[self.df_companies['ticker'].isin(self.tickers)]\n",
    "\n",
    "    def merge_and_save(self):\n",
    "        df_merged = self.df_share_prices.merge(self.df_companies, on='ticker', how='left')\n",
    "        model_columns = [col for col in self.final_features if col not in ['ticker', 'date']]\n",
    "        df_filtered = df_merged.dropna(subset=model_columns)\n",
    "\n",
    "        # Optional: Keep only tickers with enough data\n",
    "        df_filtered = df_filtered.groupby('ticker').filter(lambda x: len(x) >= 60)\n",
    "\n",
    "        self.df_cleaned = df_filtered[self.final_features]\n",
    "        self.df_cleaned.to_csv(self.output_file, index=False)\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        self.reset_and_clean_columns()\n",
    "        self.handle_dates_and_duplicates()\n",
    "        self.handle_nulls_and_missing()\n",
    "        self.feature_engineering()\n",
    "        self.filter_data()\n",
    "        self.merge_and_save()\n",
    "        return self.df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have df_share_prices and df_companies loaded\n",
    "selected_tickers = [\"AAPL\", \"WMT\", \"GOOG\", \"NFLX\", \"MSFT\"]\n",
    "\n",
    "etl = ETL(share_prices_df=df_share_prices, companies_df=df_companies, tickers=selected_tickers)\n",
    "df_cleaned = etl.run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'GOOG', 'MSFT', 'NFLX', 'WMT'], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['ticker'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SimFinId</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividend</th>\n",
       "      <th>Shares Outstanding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>2019-04-11</th>\n",
       "      <td>45846</td>\n",
       "      <td>81.88</td>\n",
       "      <td>81.92</td>\n",
       "      <td>80.89</td>\n",
       "      <td>81.08</td>\n",
       "      <td>77.87</td>\n",
       "      <td>1071479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>317515869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-12</th>\n",
       "      <td>45846</td>\n",
       "      <td>81.43</td>\n",
       "      <td>82.06</td>\n",
       "      <td>80.90</td>\n",
       "      <td>80.98</td>\n",
       "      <td>77.77</td>\n",
       "      <td>1249295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>317515869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-15</th>\n",
       "      <td>45846</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.13</td>\n",
       "      <td>79.91</td>\n",
       "      <td>80.40</td>\n",
       "      <td>77.22</td>\n",
       "      <td>1627268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>317515869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-16</th>\n",
       "      <td>45846</td>\n",
       "      <td>80.82</td>\n",
       "      <td>80.96</td>\n",
       "      <td>77.19</td>\n",
       "      <td>77.55</td>\n",
       "      <td>74.48</td>\n",
       "      <td>3441597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>317515869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-17</th>\n",
       "      <td>45846</td>\n",
       "      <td>78.15</td>\n",
       "      <td>78.32</td>\n",
       "      <td>74.46</td>\n",
       "      <td>75.43</td>\n",
       "      <td>72.44</td>\n",
       "      <td>4471971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>317515869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ZYXI</th>\n",
       "      <th>2024-03-08</th>\n",
       "      <td>171401</td>\n",
       "      <td>12.78</td>\n",
       "      <td>13.19</td>\n",
       "      <td>12.74</td>\n",
       "      <td>12.86</td>\n",
       "      <td>12.86</td>\n",
       "      <td>213848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32170182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-11</th>\n",
       "      <td>171401</td>\n",
       "      <td>12.83</td>\n",
       "      <td>13.07</td>\n",
       "      <td>12.67</td>\n",
       "      <td>12.69</td>\n",
       "      <td>12.69</td>\n",
       "      <td>150265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32170182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-12</th>\n",
       "      <td>171401</td>\n",
       "      <td>12.69</td>\n",
       "      <td>12.87</td>\n",
       "      <td>12.59</td>\n",
       "      <td>12.60</td>\n",
       "      <td>12.60</td>\n",
       "      <td>151053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32170182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-13</th>\n",
       "      <td>171401</td>\n",
       "      <td>12.57</td>\n",
       "      <td>12.81</td>\n",
       "      <td>12.57</td>\n",
       "      <td>12.69</td>\n",
       "      <td>12.69</td>\n",
       "      <td>89921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32170182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14</th>\n",
       "      <td>171401</td>\n",
       "      <td>12.69</td>\n",
       "      <td>12.73</td>\n",
       "      <td>12.18</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.19</td>\n",
       "      <td>313909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32170182.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5815264 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SimFinId   Open   High    Low  Close  Adj. Close   Volume  \\\n",
       "Ticker Date                                                                    \n",
       "A      2019-04-11     45846  81.88  81.92  80.89  81.08       77.87  1071479   \n",
       "       2019-04-12     45846  81.43  82.06  80.90  80.98       77.77  1249295   \n",
       "       2019-04-15     45846  81.00  81.13  79.91  80.40       77.22  1627268   \n",
       "       2019-04-16     45846  80.82  80.96  77.19  77.55       74.48  3441597   \n",
       "       2019-04-17     45846  78.15  78.32  74.46  75.43       72.44  4471971   \n",
       "...                     ...    ...    ...    ...    ...         ...      ...   \n",
       "ZYXI   2024-03-08    171401  12.78  13.19  12.74  12.86       12.86   213848   \n",
       "       2024-03-11    171401  12.83  13.07  12.67  12.69       12.69   150265   \n",
       "       2024-03-12    171401  12.69  12.87  12.59  12.60       12.60   151053   \n",
       "       2024-03-13    171401  12.57  12.81  12.57  12.69       12.69    89921   \n",
       "       2024-03-14    171401  12.69  12.73  12.18  12.19       12.19   313909   \n",
       "\n",
       "                   Dividend  Shares Outstanding  \n",
       "Ticker Date                                      \n",
       "A      2019-04-11       NaN         317515869.0  \n",
       "       2019-04-12       NaN         317515869.0  \n",
       "       2019-04-15       NaN         317515869.0  \n",
       "       2019-04-16       NaN         317515869.0  \n",
       "       2019-04-17       NaN         317515869.0  \n",
       "...                     ...                 ...  \n",
       "ZYXI   2024-03-08       NaN          32170182.0  \n",
       "       2024-03-11       NaN          32170182.0  \n",
       "       2024-03-12       NaN          32170182.0  \n",
       "       2024-03-13       NaN          32170182.0  \n",
       "       2024-03-14       NaN          32170182.0  \n",
       "\n",
       "[5815264 rows x 9 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Ticker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Ticker'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m df_share_prices\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Count number of rows per ticker\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m ticker_counts \u001b[38;5;241m=\u001b[39m df_share_prices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      7\u001b[0m ticker_counts\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124micker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Sort in descending order (most data first)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Ticker'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_share_prices.reset_index()\n",
    "\n",
    "# Count number of rows per ticker\n",
    "ticker_counts = df_share_prices['Ticker'].value_counts().reset_index()\n",
    "ticker_counts.columns = ['icker', 'row_count']\n",
    "\n",
    "# Sort in descending order (most data first)\n",
    "ticker_counts = ticker_counts.sort_values(by='row_count', ascending=False)\n",
    "\n",
    "print(\"📊 Companies with most data:\")\n",
    "print(ticker_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert level_0, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j5/fqsjcqyn0ms_327l9fbr9tr80000gn/T/ipykernel_79549/2073856025.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Resetting the index and converting columns to lower case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_share_prices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_companies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_share_prices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_share_prices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf_companies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_companies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[1;32m   6468\u001b[0m                     level_values = algorithms.take(\n\u001b[1;32m   6469\u001b[0m                         \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_na_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6470\u001b[0m                     \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6472\u001b[0;31m                 new_obj.insert(\n\u001b[0m\u001b[1;32m   6473\u001b[0m                     \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6474\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6475\u001b[0m                     \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5154\u001b[0m                 \u001b[0;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5157\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5158\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mcannot insert \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m, already exists\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5160\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc must be int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5161\u001b[0m         \u001b[0;31m# convert non stdlib ints to satisfy typing checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert level_0, already exists"
     ]
    }
   ],
   "source": [
    "# Resetting the index and converting columns to lower case\n",
    "\n",
    "df_share_prices.reset_index(inplace=True)\n",
    "df_companies.reset_index(inplace=True)\n",
    "df_share_prices.columns = df_share_prices.columns.str.lower()\n",
    "df_companies.columns = df_companies.columns.str.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Companies with most data:\n",
      "     icker  row_count\n",
      "0        A       1240\n",
      "2198   BRN       1240\n",
      "2188  DBVT       1240\n",
      "2189   DBX       1240\n",
      "2190   BWA       1240\n",
      "...    ...        ...\n",
      "5582  TCDA          1\n",
      "5583   RDC          1\n",
      "5584  CLVS          1\n",
      "5585   PNT          1\n",
      "5586  AMEH          1\n",
      "\n",
      "[5587 rows x 2 columns]\n",
      "🏢 Full Company Names:\n",
      "     ticker               company name\n",
      "861     BRN  Barnwell Industries, Inc.\n",
      "912     BWA             BORGWARNER INC\n",
      "1552   DBVT      DBV Technologies S.A.\n",
      "1553    DBX              DROPBOX, INC.\n"
     ]
    }
   ],
   "source": [
    "ticker_counts = df_share_prices['ticker'].value_counts().reset_index()\n",
    "ticker_counts.columns = ['icker', 'row_count']\n",
    "\n",
    "# Sort in descending order (most data first)\n",
    "ticker_counts = ticker_counts.sort_values(by='row_count', ascending=False)\n",
    "\n",
    "print(\"📊 Companies with most data:\")\n",
    "print(ticker_counts)\n",
    "\n",
    "# List of tickers you're interested in\n",
    "top_tickers = ['BRN', 'DBVT', 'DBX', 'BWA']\n",
    "\n",
    "# Ensure columns are lowercase (if not already)\n",
    "df_companies.columns = df_companies.columns.str.lower()\n",
    "\n",
    "# Filter for those tickers\n",
    "top_company_names = df_companies[df_companies['ticker'].isin(top_tickers)][['ticker', 'company name']]\n",
    "\n",
    "print(\"🏢 Full Company Names:\")\n",
    "print(top_company_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_share_prices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_share_prices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Drop duplicate rows\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df_companies\u001b[38;5;241m.\u001b[39mdrop_duplicates(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "\n",
    "df_share_prices['date'] = pd.to_datetime(df_share_prices['date'], errors='coerce')\n",
    "\n",
    "# Drop duplicate rows\n",
    "df_companies.drop_duplicates(inplace=True)\n",
    "df_share_prices.drop_duplicates(inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "df_companies.fillna(method='ffill', inplace=True)  # Forward fill missing company data\n",
    "df_share_prices.fillna(method='ffill', inplace=True)  # Forward fill stock prices\n",
    "\n",
    "# Remove rows where essential data is missing\n",
    "df_share_prices.dropna(subset=['close'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Q1 \u001b[38;5;241m=\u001b[39m df_share_prices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.25\u001b[39m)\n\u001b[1;32m      2\u001b[0m Q3 \u001b[38;5;241m=\u001b[39m df_share_prices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.75\u001b[39m)\n\u001b[1;32m      3\u001b[0m IQR \u001b[38;5;241m=\u001b[39m Q3 \u001b[38;5;241m-\u001b[39m Q1\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'close'"
     ]
    }
   ],
   "source": [
    "Q1 = df_share_prices['close'].quantile(0.25)\n",
    "Q3 = df_share_prices['close'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df_share_prices = df_share_prices[(df_share_prices['close'] >= lower_bound) & (df_share_prices['close'] <= upper_bound)]\n",
    "\n",
    "# Feature Engineering - Create lag and moving average features\n",
    "df_share_prices['prev_close'] = df_share_prices.groupby('ticker')['close'].shift(1)\n",
    "df_share_prices['ma7'] = df_share_prices.groupby('ticker')['close'].transform(lambda x: x.rolling(7).mean())\n",
    "df_share_prices['ma30'] = df_share_prices.groupby('ticker')['close'].transform(lambda x: x.rolling(30).mean())\n",
    "\n",
    "# Merge company details with share prices\n",
    "df_cleaned = df_share_prices.merge(df_companies, on='ticker', how='left')\n",
    "\n",
    "df_cleaned.to_csv('cleaned_stock_data.csv', index=False)\n",
    "print(\"✅ Data saved as 'cleaned_stock_data.csv' instead of Excel due to size limitations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>simfinid_x</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj. close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividend</th>\n",
       "      <th>...</th>\n",
       "      <th>simfinid_y</th>\n",
       "      <th>company name</th>\n",
       "      <th>industryid</th>\n",
       "      <th>isin</th>\n",
       "      <th>end of financial year (month)</th>\n",
       "      <th>number employees</th>\n",
       "      <th>business summary</th>\n",
       "      <th>market</th>\n",
       "      <th>cik</th>\n",
       "      <th>main currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2019-04-11</td>\n",
       "      <td>45846</td>\n",
       "      <td>81.88</td>\n",
       "      <td>81.92</td>\n",
       "      <td>80.89</td>\n",
       "      <td>81.08</td>\n",
       "      <td>77.87</td>\n",
       "      <td>1071479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>45846</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "      <td>106001.0</td>\n",
       "      <td>US00846U1016</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16400.0</td>\n",
       "      <td>Agilent Technologies Inc is engaged in life sc...</td>\n",
       "      <td>us</td>\n",
       "      <td>1090872.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>45846</td>\n",
       "      <td>81.43</td>\n",
       "      <td>82.06</td>\n",
       "      <td>80.90</td>\n",
       "      <td>80.98</td>\n",
       "      <td>77.77</td>\n",
       "      <td>1249295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>45846</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "      <td>106001.0</td>\n",
       "      <td>US00846U1016</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16400.0</td>\n",
       "      <td>Agilent Technologies Inc is engaged in life sc...</td>\n",
       "      <td>us</td>\n",
       "      <td>1090872.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>45846</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.13</td>\n",
       "      <td>79.91</td>\n",
       "      <td>80.40</td>\n",
       "      <td>77.22</td>\n",
       "      <td>1627268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>45846</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "      <td>106001.0</td>\n",
       "      <td>US00846U1016</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16400.0</td>\n",
       "      <td>Agilent Technologies Inc is engaged in life sc...</td>\n",
       "      <td>us</td>\n",
       "      <td>1090872.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2019-04-16</td>\n",
       "      <td>45846</td>\n",
       "      <td>80.82</td>\n",
       "      <td>80.96</td>\n",
       "      <td>77.19</td>\n",
       "      <td>77.55</td>\n",
       "      <td>74.48</td>\n",
       "      <td>3441597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>45846</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "      <td>106001.0</td>\n",
       "      <td>US00846U1016</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16400.0</td>\n",
       "      <td>Agilent Technologies Inc is engaged in life sc...</td>\n",
       "      <td>us</td>\n",
       "      <td>1090872.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2019-04-17</td>\n",
       "      <td>45846</td>\n",
       "      <td>78.15</td>\n",
       "      <td>78.32</td>\n",
       "      <td>74.46</td>\n",
       "      <td>75.43</td>\n",
       "      <td>72.44</td>\n",
       "      <td>4471971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>45846</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "      <td>106001.0</td>\n",
       "      <td>US00846U1016</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16400.0</td>\n",
       "      <td>Agilent Technologies Inc is engaged in life sc...</td>\n",
       "      <td>us</td>\n",
       "      <td>1090872.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5023036</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>171401</td>\n",
       "      <td>12.69</td>\n",
       "      <td>12.73</td>\n",
       "      <td>12.18</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.19</td>\n",
       "      <td>313909</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>7962794</td>\n",
       "      <td>BurgerFi International, Inc.</td>\n",
       "      <td>106004.0</td>\n",
       "      <td>US98986M1036</td>\n",
       "      <td>12.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>Zynex, Inc. engages in the design, manufacture...</td>\n",
       "      <td>us</td>\n",
       "      <td>1705873.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5023037</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>171401</td>\n",
       "      <td>12.69</td>\n",
       "      <td>12.73</td>\n",
       "      <td>12.18</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.19</td>\n",
       "      <td>313909</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>689587</td>\n",
       "      <td>BurgerFi International, Inc.</td>\n",
       "      <td>106004.0</td>\n",
       "      <td>US98986M1036</td>\n",
       "      <td>12.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>Zynex, Inc. engages in the design, manufacture...</td>\n",
       "      <td>us</td>\n",
       "      <td>1705873.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5023038</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>171401</td>\n",
       "      <td>12.69</td>\n",
       "      <td>12.73</td>\n",
       "      <td>12.18</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.19</td>\n",
       "      <td>313909</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>6480955</td>\n",
       "      <td>BurgerFi International, Inc.</td>\n",
       "      <td>106004.0</td>\n",
       "      <td>US98986M1036</td>\n",
       "      <td>12.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>Zynex, Inc. engages in the design, manufacture...</td>\n",
       "      <td>us</td>\n",
       "      <td>1906324.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5023039</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>171401</td>\n",
       "      <td>12.69</td>\n",
       "      <td>12.73</td>\n",
       "      <td>12.18</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.19</td>\n",
       "      <td>313909</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>6481013</td>\n",
       "      <td>BurgerFi International, Inc.</td>\n",
       "      <td>106004.0</td>\n",
       "      <td>US98986M1036</td>\n",
       "      <td>12.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>Zynex, Inc. engages in the design, manufacture...</td>\n",
       "      <td>us</td>\n",
       "      <td>1130464.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5023040</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>171401</td>\n",
       "      <td>12.69</td>\n",
       "      <td>12.73</td>\n",
       "      <td>12.18</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.19</td>\n",
       "      <td>313909</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>6481030</td>\n",
       "      <td>BurgerFi International, Inc.</td>\n",
       "      <td>106004.0</td>\n",
       "      <td>US98986M1036</td>\n",
       "      <td>12.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>Zynex, Inc. engages in the design, manufacture...</td>\n",
       "      <td>us</td>\n",
       "      <td>1692115.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5023041 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ticker       date  simfinid_x   open   high    low  close  adj. close  \\\n",
       "0            A 2019-04-11       45846  81.88  81.92  80.89  81.08       77.87   \n",
       "1            A 2019-04-12       45846  81.43  82.06  80.90  80.98       77.77   \n",
       "2            A 2019-04-15       45846  81.00  81.13  79.91  80.40       77.22   \n",
       "3            A 2019-04-16       45846  80.82  80.96  77.19  77.55       74.48   \n",
       "4            A 2019-04-17       45846  78.15  78.32  74.46  75.43       72.44   \n",
       "...        ...        ...         ...    ...    ...    ...    ...         ...   \n",
       "5023036   ZYXI 2024-03-14      171401  12.69  12.73  12.18  12.19       12.19   \n",
       "5023037   ZYXI 2024-03-14      171401  12.69  12.73  12.18  12.19       12.19   \n",
       "5023038   ZYXI 2024-03-14      171401  12.69  12.73  12.18  12.19       12.19   \n",
       "5023039   ZYXI 2024-03-14      171401  12.69  12.73  12.18  12.19       12.19   \n",
       "5023040   ZYXI 2024-03-14      171401  12.69  12.73  12.18  12.19       12.19   \n",
       "\n",
       "          volume  dividend  ...  simfinid_y                  company name  \\\n",
       "0        1071479       NaN  ...       45846      AGILENT TECHNOLOGIES INC   \n",
       "1        1249295       NaN  ...       45846      AGILENT TECHNOLOGIES INC   \n",
       "2        1627268       NaN  ...       45846      AGILENT TECHNOLOGIES INC   \n",
       "3        3441597       NaN  ...       45846      AGILENT TECHNOLOGIES INC   \n",
       "4        4471971       NaN  ...       45846      AGILENT TECHNOLOGIES INC   \n",
       "...          ...       ...  ...         ...                           ...   \n",
       "5023036   313909       0.1  ...     7962794  BurgerFi International, Inc.   \n",
       "5023037   313909       0.1  ...      689587  BurgerFi International, Inc.   \n",
       "5023038   313909       0.1  ...     6480955  BurgerFi International, Inc.   \n",
       "5023039   313909       0.1  ...     6481013  BurgerFi International, Inc.   \n",
       "5023040   313909       0.1  ...     6481030  BurgerFi International, Inc.   \n",
       "\n",
       "         industryid          isin  end of financial year (month)  \\\n",
       "0          106001.0  US00846U1016                           10.0   \n",
       "1          106001.0  US00846U1016                           10.0   \n",
       "2          106001.0  US00846U1016                           10.0   \n",
       "3          106001.0  US00846U1016                           10.0   \n",
       "4          106001.0  US00846U1016                           10.0   \n",
       "...             ...           ...                            ...   \n",
       "5023036    106004.0  US98986M1036                           12.0   \n",
       "5023037    106004.0  US98986M1036                           12.0   \n",
       "5023038    106004.0  US98986M1036                           12.0   \n",
       "5023039    106004.0  US98986M1036                           12.0   \n",
       "5023040    106004.0  US98986M1036                           12.0   \n",
       "\n",
       "        number employees                                   business summary  \\\n",
       "0                16400.0  Agilent Technologies Inc is engaged in life sc...   \n",
       "1                16400.0  Agilent Technologies Inc is engaged in life sc...   \n",
       "2                16400.0  Agilent Technologies Inc is engaged in life sc...   \n",
       "3                16400.0  Agilent Technologies Inc is engaged in life sc...   \n",
       "4                16400.0  Agilent Technologies Inc is engaged in life sc...   \n",
       "...                  ...                                                ...   \n",
       "5023036            768.0  Zynex, Inc. engages in the design, manufacture...   \n",
       "5023037            768.0  Zynex, Inc. engages in the design, manufacture...   \n",
       "5023038            768.0  Zynex, Inc. engages in the design, manufacture...   \n",
       "5023039            768.0  Zynex, Inc. engages in the design, manufacture...   \n",
       "5023040            768.0  Zynex, Inc. engages in the design, manufacture...   \n",
       "\n",
       "        market        cik  main currency  \n",
       "0           us  1090872.0            USD  \n",
       "1           us  1090872.0            USD  \n",
       "2           us  1090872.0            USD  \n",
       "3           us  1090872.0            USD  \n",
       "4           us  1090872.0            USD  \n",
       "...        ...        ...            ...  \n",
       "5023036     us  1705873.0            USD  \n",
       "5023037     us  1705873.0            USD  \n",
       "5023038     us  1906324.0            USD  \n",
       "5023039     us  1130464.0            USD  \n",
       "5023040     us  1692115.0            USD  \n",
       "\n",
       "[5023041 rows x 24 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticker', 'date', 'simfinid_x', 'open', 'high', 'low', 'close',\n",
       "       'adj. close', 'volume', 'dividend', 'shares outstanding', 'prev_close',\n",
       "       'ma7', 'ma30', 'simfinid_y', 'company name', 'industryid', 'isin',\n",
       "       'end of financial year (month)', 'number employees', 'business summary',\n",
       "       'market', 'cik', 'main currency'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Filtered dataset saved as 'filtered_stock_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned stock data\n",
    "df = pd.read_csv(\"cleaned_stock_data.csv\")\n",
    "\n",
    "# Define the tickers to keep\n",
    "selected_tickers = [\"AAPL\", \"WMT\", \"GOOG\", \"TSLA\", \"NVDA\"]\n",
    "\n",
    "# Filter the dataset for only these tickers\n",
    "df_filtered = df[df[\"ticker\"].isin(selected_tickers)]\n",
    "\n",
    "# Save the filtered dataset to a new CSV file\n",
    "df_filtered.to_csv(\"filtered_5_companies_stock_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ Filtered dataset saved as 'filtered_stock_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "✅ Model Accuracy: 0.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.35      0.47        31\n",
      "           1       0.66      0.88      0.75        43\n",
      "\n",
      "    accuracy                           0.66        74\n",
      "   macro avg       0.67      0.62      0.61        74\n",
      "weighted avg       0.67      0.66      0.63        74\n",
      "\n",
      "📊 Prediction for GOOG on the next trading day: Up 📈\n",
      "✅ Model saved as 'GOOG_trend_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Load cleaned stock data\n",
    "df = pd.read_csv('cleaned_stock_data.csv')\n",
    "\n",
    "# 🔹 User Input: Select a Company\n",
    "company_ticker = input(\"Enter the company ticker (e.g., GOOGL, AAPL, MSFT): \").strip().upper()\n",
    "\n",
    "# 🔹 Check if the company exists\n",
    "if company_ticker not in df['ticker'].unique():\n",
    "    print(f\"❌ Error: Company '{company_ticker}' not found in dataset.\")\n",
    "    exit()\n",
    "\n",
    "# Filter for selected company\n",
    "df_company = df[df['ticker'] == company_ticker].copy()\n",
    "\n",
    "# Convert 'date' to datetime and sort by date\n",
    "df_company['date'] = pd.to_datetime(df_company['date'])\n",
    "df_company = df_company.sort_values(by='date')\n",
    "\n",
    "# 🔹 Create Target Variable: Trend Prediction (1 = Up, 0 = Down)\n",
    "df_company['trend'] = (df_company['close'].shift(-1) > df_company['close']).astype(int)\n",
    "\n",
    "# Drop last row (no future data)\n",
    "df_company = df_company[:-1]\n",
    "\n",
    "# 🔹 Feature Engineering\n",
    "df_company['daily_return'] = df_company['close'].pct_change()\n",
    "df_company['volatility'] = df_company['close'].rolling(7).std()\n",
    "df_company['ma7'] = df_company['close'].rolling(7).mean()\n",
    "df_company['ma30'] = df_company['close'].rolling(30).mean()\n",
    "df_company.dropna(inplace=True)  # Remove NaN values\n",
    "\n",
    "# 🔹 Prepare Training Data\n",
    "features = ['close', 'daily_return', 'volatility', 'ma7', 'ma30']\n",
    "X = df_company[features]\n",
    "y = df_company['trend']\n",
    "\n",
    "# Split into training & testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 🔹 Hyperparameter Tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get Best Model\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"✅ Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"✅ Model Accuracy: {accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 🔹 Predict Next Day's Trend\n",
    "latest_data = X.iloc[[-1]]  # Get the most recent day’s features\n",
    "prediction = best_model.predict(latest_data)\n",
    "\n",
    "# Show Prediction\n",
    "trend_prediction = \"Up 📈\" if prediction[0] == 1 else \"Down 📉\"\n",
    "print(f\"📊 Prediction for {company_ticker} on the next trading day: {trend_prediction}\")\n",
    "\n",
    "# Save Model\n",
    "joblib.dump(best_model, f'{company_ticker}_trend_model.pkl')\n",
    "print(f\"✅ Model saved as '{company_ticker}_trend_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
