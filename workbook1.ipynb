{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simfin in /opt/anaconda3/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from simfin) (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from simfin) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from simfin) (2.32.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->simfin) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->simfin) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->simfin) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->simfin) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->simfin) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->simfin) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->simfin) (2024.6.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->simfin) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install simfin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '9104e7ab-b221-4476-89fe-0f3e0300ad24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"us-income-annual\" not on disk.\n",
      "- Downloading ... 100.0%\n",
      "- Extracting zip-file ... Done!\n",
      "- Loading from disk ... Done!\n",
      "                  Revenue   Net Income\n",
      "Report Date                           \n",
      "2019-06-30   1.258430e+11  39240000000\n",
      "2020-06-30   1.430150e+11  44281000000\n",
      "2021-06-30   1.680880e+11  61271000000\n",
      "2022-06-30   1.982700e+11  72738000000\n",
      "2023-06-30   2.119150e+11  72361000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/simfin/load.py:154: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  df = pd.read_csv(path, sep=';', header=0,\n"
     ]
    }
   ],
   "source": [
    "import simfin as sf\n",
    "from simfin.names import *\n",
    "\n",
    "# Set your API-key for downloading data.\n",
    "# Replace YOUR_API_KEY with your actual API-key.\n",
    "sf.set_api_key(api_key)\n",
    "\n",
    "# Set the local directory where data-files are stored.\n",
    "# The dir will be created if it does not already exist.\n",
    "sf.set_data_dir('~/simfin_data/')\n",
    "\n",
    "# Load the annual Income Statements for all companies in the US.\n",
    "# The data is automatically downloaded if you don't have it already.\n",
    "df = sf.load_income(variant='annual', market='us')\n",
    "\n",
    "# Print all Revenue and Net Income for Microsoft (ticker MSFT).\n",
    "print(df.loc['MSFT', [REVENUE, NET_INCOME]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in share_prices_df: ['Ticker', 'SimFinId', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj. Close', 'Volume', 'Dividend', 'Shares Outstanding']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['industry'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprev_close\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mma7\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mma30\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindustry\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     55\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext_day_close\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 57\u001b[0m X \u001b[38;5;241m=\u001b[39m cleaned_data[features]\n\u001b[1;32m     58\u001b[0m y \u001b[38;5;241m=\u001b[39m cleaned_data[target]\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Train-Test Split\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['industry'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load datasets with improved error handling\n",
    "companies_df = pd.read_csv('us-companies.csv', sep=None, engine='python', on_bad_lines='skip', encoding='utf-8')\n",
    "share_prices_df = pd.read_csv('us-shareprices-daily.csv', sep=None, engine='python', on_bad_lines='skip', encoding='utf-8')\n",
    "\n",
    "# Strip column names of any whitespace\n",
    "share_prices_df.columns = share_prices_df.columns.str.strip()\n",
    "companies_df.columns = companies_df.columns.str.strip()\n",
    "\n",
    "# Print column names for debugging\n",
    "print(\"Columns in share_prices_df:\", share_prices_df.columns.tolist())\n",
    "\n",
    "# Ensure 'ticker' column exists before filtering\n",
    "if 'Ticker' in share_prices_df.columns:\n",
    "    apple_data = share_prices_df[share_prices_df['Ticker'] == 'AAPL']\n",
    "else:\n",
    "    raise KeyError(\"The 'ticker' column is missing from share_prices_df.\")\n",
    "\n",
    "# Merge datasets on the common key (assuming 'ticker' is the identifier)\n",
    "apple_data = apple_data.merge(companies_df, on='Ticker', how='left')\n",
    "\n",
    "# Convert date column to datetime format\n",
    "apple_data['date'] = pd.to_datetime(apple_data['Date'], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "apple_data = apple_data.dropna(subset=['date'])\n",
    "\n",
    "# Sort by date\n",
    "apple_data.sort_values(by='date', inplace=True)\n",
    "\n",
    "# Feature Engineering: Create lag features (previous day's price)\n",
    "apple_data['prev_close'] = apple_data['Close'].shift(1)\n",
    "\n",
    "# Moving Averages (e.g., 7-day and 30-day)\n",
    "apple_data['ma7'] = apple_data['Close'].rolling(7).mean()\n",
    "apple_data['ma30'] = apple_data['Close'].rolling(30).mean()\n",
    "\n",
    "# Target Variable: Next day close price\n",
    "apple_data['next_day_close'] = apple_data['Close'].shift(-1)\n",
    "\n",
    "# Drop rows with NaN values introduced by shifting\n",
    "cleaned_data = apple_data.dropna()\n",
    "\n",
    "# Encode categorical variables (e.g., industry)\n",
    "if 'industry' in cleaned_data.columns:\n",
    "    le = LabelEncoder()\n",
    "    cleaned_data['industry'] = le.fit_transform(cleaned_data['industry'].astype(str))\n",
    "\n",
    "# Select relevant columns for modeling\n",
    "features = ['prev_close', 'ma7', 'ma30', 'industry']\n",
    "target = 'next_day_close'\n",
    "\n",
    "X = cleaned_data[features]\n",
    "y = cleaned_data[target]\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=features)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=features)\n",
    "\n",
    "# Save processed data\n",
    "X_train.to_csv('/mnt/data/X_train.csv', index=False)\n",
    "X_test.to_csv('/mnt/data/X_test.csv', index=False)\n",
    "y_train.to_csv('/mnt/data/y_train.csv', index=False)\n",
    "y_test.to_csv('/mnt/data/y_test.csv', index=False)\n",
    "\n",
    "print(\"ETL process completed for Apple. Processed datasets saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
